<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><entry><title type="html">How to print logs in JSON format in WildFly</title><link rel="alternate" href="http://www.mastertheboss.com/jbossas/jboss-log/how-to-print-logs-in-json-format-in-wildfly/" /><author><name>F.Marchioni</name></author><id>http://www.mastertheboss.com/jbossas/jboss-log/how-to-print-logs-in-json-format-in-wildfly/</id><updated>2023-02-06T09:32:44Z</updated><content type="html">This article discusses the configuration you can apply in WildFly to enable logging in JSON format. We will learn how to do that natively in WildFly or using a Log4j custom configuration. Strategies for logging in JSON There are several use cases in which logging in JSON format can be useful. For example: Use cases ... The post appeared first on .</content><dc:creator>F.Marchioni</dc:creator></entry><entry><title type="html">How to compress logs in WildFly</title><link rel="alternate" href="http://www.mastertheboss.com/jbossas/jboss-log/how-to-compress-logs-in-wildfly/" /><author><name>F.Marchioni</name></author><id>http://www.mastertheboss.com/jbossas/jboss-log/how-to-compress-logs-in-wildfly/</id><updated>2023-02-06T09:12:23Z</updated><content type="html">This article shows how to enable logs compression in WildFly by setting the appropriate suffix in your Periodic Rotating File Handler. In the second part of this tutorial we will learn how to compress logs using Log4j instead. Compressing Logs natively with WildFly Logs are an essential part of any software application, as they help ... The post appeared first on .</content><dc:creator>F.Marchioni</dc:creator></entry><entry><title type="html">How to set the SameSite attribute in Java Web applications</title><link rel="alternate" href="http://www.mastertheboss.com/web/jboss-web-server/how-to-set-the-samesite-attribute-in-java-web-applications/" /><author><name>F.Marchioni</name></author><id>http://www.mastertheboss.com/web/jboss-web-server/how-to-set-the-samesite-attribute-in-java-web-applications/</id><updated>2023-02-06T07:43:46Z</updated><content type="html">This short article describes how you can set the SameSite property in HTTP Cookies for Web applications, with special focus on WildFly‘s Web server, which is Undertow. What is SameSite ? SameSite is a property that you can set in HTTP cookies to avoid false cross-site request (CSRF) attacks in web applications: When SameSite is ... The post appeared first on .</content><dc:creator>F.Marchioni</dc:creator></entry><entry><title>How to improve application security using _FORTIFY_SOURCE=3</title><link rel="alternate" href="https://developers.redhat.com/articles/2023/02/06/how-improve-application-security-using-fortifysource3" /><author><name>Siddhesh Poyarekar</name></author><id>4972acb7-3c57-4a83-94dd-f13813593ac1</id><updated>2023-02-06T07:00:00Z</updated><published>2023-02-06T07:00:00Z</published><summary type="html">&lt;p&gt;Last year I wrote about the &lt;a href="https://developers.redhat.com/articles/2022/09/17/gccs-new-fortification-level"&gt;new level for _FORTIFY_SOURCE&lt;/a&gt; and how it promises to significantly improve application security mitigation in C/C++. In this article, I will show you how an application or library developer can get the best possible fortification results from the compiler to improve the security of applications deployed on &lt;a href="https://www.redhat.com/en/technologies/linux-platforms/enterprise-linux"&gt;Red Hat Enterprise Linux&lt;/a&gt;, for instance. There are shades of previous articles about GCC. But that just goes to show how compiler features tie in together to provide security protection at multiple levels, from prevention to mitigation. First, we should take a closer look at the potential impact of &lt;code&gt;_FORTIFY_SOURCE=3&lt;/code&gt; on performance and code size of applications.&lt;/p&gt; &lt;h2&gt;The performance impact of the new fortification level&lt;/h2&gt; &lt;p&gt;The &lt;code&gt;_FORTIFY_SOURCE=3&lt;/code&gt; builtin improves fortification coverage by evaluating and passing size expressions instead of the constants seen in &lt;code&gt;_FORTIFY_SOURCE=2&lt;/code&gt;, which generates additional code and potentially more register pressure. But the impact of that additional code appears to be trivial in practice. When I compared nearly &lt;a href="https://docs.google.com/spreadsheets/d/1nPSmbEf3HVB91zI8yBraMqVry3_ILmlV2Z5K7FZeHZg/edit?usp=sharing"&gt;10 thousand packages&lt;/a&gt; in Fedora rawhide, I found barely any impact on code size. Some binaries grew while others shrunk, indicating a change in generated code, but there was no broad increase in code size.&lt;/p&gt; &lt;p&gt;However, given that the code did change, surely we should see side effects such as register pressure, shouldn't we? Again in practice, that side effect turns out to be trivial. Running SPEC benchmarks with &lt;code&gt;_FORTIFY_SOURCE=3&lt;/code&gt; again showed no slowdown at all compared to &lt;code&gt;_FORTIFY_SOURCE=2&lt;/code&gt;, indicating that there is no broad-based impact on performance due to this new fortification level. The results are not entirely surprising, though, if you put them in the context of typical programs, modern processors, and how &lt;code&gt;_FORTIFY_SOURCE=3&lt;/code&gt; works.&lt;/p&gt; &lt;h3&gt;Does object size overhead affect performance?&lt;/h3&gt; &lt;p&gt;At a high level, the major purpose of the &lt;code&gt;_FORTIFY_SOURCE=3&lt;/code&gt; feature is to estimate the size of an object passed to a library function call and ensure that the call does not perform any unsafe actions on that object and abort if it does. The success of &lt;code&gt;_FORTIFY_SOURCE&lt;/code&gt; as a mitigation strategy is directly linked to its ability to estimate the size of the passed object.&lt;/p&gt; &lt;p&gt;Now there are two main vectors for performance overhead due to this:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;Overhead of a fortified call instead of the regular call (e.g., &lt;code&gt;__memcpy_chk&lt;/code&gt; for &lt;code&gt;memcpy&lt;/code&gt;). This is significant because, in theory, &lt;code&gt;_FORTIFY_SOURCE=3&lt;/code&gt; should generate many more of these than &lt;code&gt;_FORTIFY_SOURCE=2&lt;/code&gt;.&lt;/li&gt; &lt;li&gt;Overhead of the size expression that is passed to the fortified call instead of the constant in &lt;code&gt;_FORTIFY_SOURCE=2&lt;/code&gt;.&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;The function call overhead isn't a big enough concern for two main reasons. The most important reason is that in many cases where the size of an object is visible, the compiler is determined conclusively at compile time that the access is safe. Thank the wonderful work on &lt;a href="https://developers.redhat.com/blog/2021/04/28/value-range-propagation-in-gcc-with-project-ranger"&gt;value range propagation&lt;/a&gt; that went into GCC in recent years for this. Due to this, the compiler can, in those cases, avoid fortifying the call and instead use the regular library function call.&lt;/p&gt; &lt;p&gt;In cases where the fortified call is unavoidable, the overhead will be noticeable only if the call is encountered repeatedly (i.e., it is on the hot path). Here's where modern CPUs come into the picture with their well-oiled branch predictors. The branches for access safety validation are always predicted correctly, and the processor sails through them almost as if they weren't there.&lt;/p&gt; &lt;p&gt;The overhead of size expressions is slightly trickier to explain but still intuitive enough. Whenever &lt;code&gt;_FORTIFY_SOURCE=3&lt;/code&gt; is successful in determining the size estimate for an object, it basically has access to the definition of that object, which either gives it a readily available constant or expression for use. Additionally, any derivative arithmetic the compiler needs to generate for the object access (e.g., &lt;code&gt;&amp;buf-&gt;member.data[1] + i&lt;/code&gt;) is often the same arithmetic to get the final size of the pointer, which the compiler appears to reliably meld together, thereby nullifying any such overhead.&lt;/p&gt; &lt;h3&gt;Final verdict on performance impact&lt;/h3&gt; &lt;p&gt;One might be tempted to conclude that there is absolutely no performance overhead to building applications with &lt;code&gt;_FORTIFY_SOURCE=3&lt;/code&gt; , but it is more nuanced than that. In most cases, the performance overhead appears negligible due to the compiler being smart enough to optimize most of the overhead away. As a result, it should be safe for most application developers to simply bump up fortification to &lt;code&gt;_FORTIFY_SOURCE=3&lt;/code&gt; and be done with it.&lt;/p&gt; &lt;p&gt;Now let's look at how application developers can get the most out of &lt;code&gt;_FORTIFY_SOURCE=3&lt;/code&gt;.&lt;/p&gt; &lt;h2&gt;How to improve application fortification&lt;/h2&gt; &lt;p&gt;The primary way to improve the success of &lt;code&gt;_FORTIFY_SOURCE&lt;/code&gt; is to tell the compiler about the size of an object passed into a function. The compiler can evaluate simple cases where objects are plain types or structures with constant sizes almost all the time. However, objects that are dynamically allocated and whose pointers are passed to a function are tricky. There are several ways to tell the compiler that. These hints are supported by GCC and Clang, so it does not matter which of those two compilers you use. Additionally, these attributes can be applied to C and C++ functions, so this is not limited to just C.&lt;/p&gt; &lt;p&gt;Note that these benefits don't just improve fortification. Since they end up giving better object size information, they improve overall diagnostics, which means better warnings and often even faster code.&lt;/p&gt; &lt;h3&gt;Using allocator functions&lt;/h3&gt; &lt;p&gt;If your application uses allocators provided by the standard library (e.g., &lt;code&gt;malloc&lt;/code&gt;, &lt;code&gt;realloc&lt;/code&gt;, etc.), the compiler can automatically use the size argument passed to those functions as the object size. However, if your application has wrappers that do special things before or after allocation, or if your application has bespoke allocator functions, you could decorate those functions with the &lt;code&gt;__alloc_size__&lt;/code&gt; attribute to indicate which of the arguments to your allocation function is the size of the returned object.&lt;/p&gt; &lt;p&gt;This is how it would look:&lt;/p&gt; &lt;p&gt;&lt;code&gt;void *my_allocator (size_t sz) __attribute__ ((__alloc_size__ (1)));&lt;/code&gt;&lt;/p&gt; &lt;p&gt;For a calloc-like allocator, it would be:&lt;/p&gt; &lt;p&gt;&lt;code&gt;void *my_allocator (size_t nmemb, size_t size) __attribute__ ((__alloc_size__ (1, 2)));&lt;/code&gt;&lt;/p&gt; &lt;p&gt;In the first case, the compiler will see that the size of the allocated object is &lt;code&gt;sz&lt;/code&gt;. In the second case, it will see the size as &lt;code&gt;nmemb * size&lt;/code&gt;.&lt;/p&gt; &lt;h3&gt;How to use the __access__ function attribute&lt;/h3&gt; &lt;p&gt;In C, a typical programming practice is that when pointers are passed to a function to access arrays, the size of the array the pointer points to is typically passed as another argument to that function. If your application or library uses this pattern, then you may be able to tell the compiler about this size using the &lt;code&gt;__access__&lt;/code&gt; function attribute on the definition of that function. This attribute is a GCC extension, also available in Clang. The following example tells the compiler that &lt;code&gt;ptr&lt;/code&gt; points to memory that is safe to read and write to the extent of &lt;code&gt;sz&lt;/code&gt; bytes.&lt;/p&gt; &lt;p&gt;&lt;code&gt;void&lt;br /&gt; __attribute__ ((__access__ (__read_write__, 1, 2)))&lt;br /&gt; do_something (char *ptr, size_t sz)&lt;/code&gt;&lt;br /&gt;&lt;code&gt;{&lt;br /&gt;   ...&lt;/code&gt;&lt;br /&gt;&lt;code&gt;  // Get a copy size from somewhere else.&lt;/code&gt;&lt;br /&gt;&lt;code&gt;  size_t setsize = get_size ();&lt;br /&gt;   memset (ptr, 0, setsize);&lt;br /&gt; }&lt;/code&gt;&lt;/p&gt; &lt;p&gt;Put the attribute in the function declaration and the definition because the compiler uses it to validate call sites and perform analysis and fortification within the implementation. At the call site, the value passed for &lt;code&gt;sz&lt;/code&gt; is validated against the size of the object pointed to by &lt;code&gt;ptr&lt;/code&gt; to ensure that &lt;code&gt;do_something&lt;/code&gt; can safely access &lt;code&gt;sz&lt;/code&gt; elements in &lt;code&gt;ptr&lt;/code&gt;. Any inconsistency is flagged as a compile time warning. Inside the function implementation, &lt;code&gt;sz&lt;/code&gt; is assumed to be the size of &lt;code&gt;ptr&lt;/code&gt; and any accesses through &lt;code&gt;ptr&lt;/code&gt; within the function are validated against &lt;code&gt;sz&lt;/code&gt;. In the &lt;code&gt;do_something&lt;/code&gt; implementation, &lt;code&gt;_FORTIFY_SOURCE&lt;/code&gt; will ensure in the call to &lt;code&gt;memset&lt;/code&gt; that &lt;code&gt;setsize&lt;/code&gt; is less than or equal to &lt;code&gt;sz&lt;/code&gt; or otherwise, abort.&lt;/p&gt; &lt;p&gt;An important note about a known issue in the compiler attributes (i.e., &lt;code&gt;__alloc_size__&lt;/code&gt; and &lt;code&gt;__access__&lt;/code&gt;:) is that these are read by the compiler only if the function it is associated with is not inlined. That is, if &lt;code&gt;do_something&lt;/code&gt; or &lt;code&gt;my_allocator&lt;/code&gt; are inlined, the compiler won't see their attributes anymore. In common cases, this should not matter too much because the inlining ideally should give just as much or more information about the object size. My advice is to correctly annotate all of the functions in the application or library.&lt;/p&gt; &lt;h3&gt;The flexible array conundrum&lt;/h3&gt; &lt;p&gt;Flexible arrays are a complex topic because of the various ways GCC and Clang support them. A flexible array is an array at the end of a structure that is dynamically allocated in the program. Before it was standardized, GCC had an extension where any array that was declared at the end of the structure with subscripts &lt;code&gt;[0]&lt;/code&gt; and &lt;code&gt;[1]&lt;/code&gt; were considered flexible arrays. C99 then formalized this with the &lt;code&gt;[]&lt;/code&gt; notation without any numeric subscript and further locked down semantics, ensuring that the flexible array always appeared at the end of a top-level structure.&lt;/p&gt; &lt;p&gt;GCC, however, continues to support the extensions and even supports flexible arrays in nested structures and unions. This makes object size computations tricky because the compiler may sometimes see the flexible arrays as zero or one-sized arrays, causing spurious crashes with &lt;code&gt;_FORTIFY_SOURCE&lt;/code&gt;. These problems can be avoided if the application uses the standard &lt;code&gt;[]&lt;/code&gt; notation for its flexible arrays.&lt;/p&gt; &lt;h2&gt;Build your applications with _FORTIFY_SOURCE=3&lt;/h2&gt; &lt;p&gt;This article has described the implications of building your application or library with &lt;code&gt;_FORTIFY_SOURCE=3&lt;/code&gt; compared to &lt;code&gt;_FORTIFY_SOURCE=2&lt;/code&gt;. The improved fortification coverage helps to make your programs significantly safer than the current state. I have provided a &lt;a href="https://github.com/siddhesh/fortify-metrics"&gt;GCC plugin&lt;/a&gt; to help you measure the fortification coverage using &lt;code&gt;_FORTIFY_SOURCE=2&lt;/code&gt; compared to &lt;code&gt;_FORTIFY_SOURCE=3&lt;/code&gt; so you can determine how much additional benefit it provides.&lt;/p&gt; &lt;p&gt;We hope to get closer to our goal of having safer applications deployed on &lt;a href="https://www.redhat.com/en/blog/hot-presses-red-hat-enterprise-linux-9"&gt;RHEL&lt;/a&gt;. We can accomplish this goal with more applications and libraries containing good compiler annotations and built with &lt;code&gt;_FORTIFY_SOURCE=3&lt;/code&gt; and with more developers fixing compiler warnings. If you have questions, please comment below. We welcome your feedback.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2023/02/06/how-improve-application-security-using-fortifysource3" title="How to improve application security using _FORTIFY_SOURCE=3"&gt;How to improve application security using _FORTIFY_SOURCE=3&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Siddhesh Poyarekar</dc:creator><dc:date>2023-02-06T07:00:00Z</dc:date></entry><entry><title type="html">Keycloak tutorial for beginners</title><link rel="alternate" href="http://www.mastertheboss.com/keycloak/introduction-to-keycloak/" /><author><name>F.Marchioni</name></author><id>http://www.mastertheboss.com/keycloak/introduction-to-keycloak/</id><updated>2023-02-02T16:15:12Z</updated><content type="html">Keycloak is an Identity and Access Management Server for Modern Applications and Services. In this Keycloak tutorial we will learn how to set up Keycloak and configure it to authenticate/authorize Enterprise applications. Keycloak update (2023) Keycloak is available in two distributions: Legacy distribution (which uses WildFly as runtime engine). Quarkus distribution (which uses Quarkus as ... The post appeared first on .</content><dc:creator>F.Marchioni</dc:creator></entry><entry><title type="html">How to use a Datasource in Quarkus</title><link rel="alternate" href="http://www.mastertheboss.com/soa-cloud/quarkus/how-to-use-a-datasource-in-quarkus/" /><author><name>F.Marchioni</name></author><id>http://www.mastertheboss.com/soa-cloud/quarkus/how-to-use-a-datasource-in-quarkus/</id><updated>2023-02-02T10:13:18Z</updated><content type="html">Agroal is a connection pool implementation that can be used with Quarkus to manage database connections. In this tutorial, we will go over how to use the DataSource in a Quarkus application. First, you’ll need to add the Agroal extension to your Quarkus application. You can do this by adding the following dependency to your ... The post appeared first on .</content><dc:creator>F.Marchioni</dc:creator></entry><entry><title>How we added support for the C++23 assume feature in GCC</title><link rel="alternate" href="https://developers.redhat.com/articles/2023/02/02/support-c23-assume-feature-gcc" /><author><name>Andrew MacLeod</name></author><id>add91dac-43e0-4e20-a731-1c64457dff13</id><updated>2023-02-02T07:00:00Z</updated><published>2023-02-02T07:00:00Z</published><summary type="html">&lt;p&gt;For the past few years, I have been working on Project Ranger, a new infrastructure in GCC that determines value ranges of variables in &lt;a href="https://developers.redhat.com/topics/c"&gt;C and C++&lt;/a&gt; programs. This article discusses how Ranger supports the new &lt;code&gt;assume&lt;/code&gt; feature of the C++23 standard, which helps programmers optimize programs.&lt;/p&gt; &lt;p&gt;Ranger is a generic system that performs basic algebraic evaluations using the known ranges of some variables to determine the possible ranges for other variables. Ranger supports several compiler optimizations. I have written two previous articles about Ranger, so please refer to them for background. &lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2019/10/11/a-upside-down-approach-to-gcc-optimizations#"&gt;An upside-down approach to GCC optimizations&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2021/04/28/value-range-propagation-in-gcc-with-project-ranger#"&gt;Value range propagation in GCC with Project Ranger&lt;/a&gt;.&lt;/li&gt; &lt;/ul&gt;&lt;h2&gt;How Ranger improves optimization&lt;/h2&gt; &lt;p&gt;The following example illustrates how Ranger can help GCC remove unnecessary C and C++ code. Assume that all values are signed 8-bit integers and that no overflows can take place.&lt;/p&gt; &lt;pre&gt; &lt;code class="cpp"&gt;x = y * 2 c = x &gt; 20 if (c) { block 1 } else { block 2 }&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Ranger works backward through the expressions, substituting known values into the results and evaluating the inputs. If the &lt;code&gt;if&lt;/code&gt; statement returns a true value (represented in C as 1), we know the following in block 1:&lt;/p&gt; &lt;pre&gt; &lt;code class="java"&gt;c = [1,1] // c has a min of 1 and a max of 1. [1, 1] = x &gt; 20 // x &gt; 20, so x = [21, 127] [21, 127] = y * 2 // y = [11, 63]&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Likewise, on the false side of the branch, we know the following in block 2:&lt;/p&gt; &lt;pre&gt; &lt;code class="java"&gt;c = [0,0] [0, 0] = x &gt; 20 // x &lt;= 20, so x = [-128, 20] [-128, 20] = y * 2 // y = [-64, 10]&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Ranger is currently being used by close to a dozen optimization passes to assist with various code transformations.&lt;/p&gt; &lt;h2&gt;An introduction to assume expressions&lt;/h2&gt; &lt;p&gt;As we neared the close of GCC 13 development, I was approached by another developer who was adding basic internal support for the new C++23 &lt;code&gt;assume&lt;/code&gt; keyword. He asked whether Ranger could be used for analysis so that &lt;code&gt;assume&lt;/code&gt; could actually be useful to the compiler.&lt;/p&gt; &lt;p&gt;I had never heard of the &lt;code&gt;assume&lt;/code&gt; keyword before this. It is a mechanism by which the C++ programmer can indicate that an arbitrarily complex expression always evaluates to true.&lt;/p&gt; &lt;p&gt;The other developer handled the feature by turning each &lt;code&gt;assume&lt;/code&gt; expression into an outlined function—a call to a small function that evaluates the expression. My task was to figure out what information we could determine about the parameters of the function based on the assumption that the function always returns a true value.&lt;/p&gt; &lt;p&gt;An example of C++ code we could analyze follows. The three input values (&lt;code&gt;x&lt;/code&gt;, &lt;code&gt;y&lt;/code&gt;, and &lt;code&gt;z&lt;/code&gt;) are unsigned.&lt;/p&gt; &lt;pre&gt; &lt;code class="cpp"&gt;int myfunc (unsigned x, unsigned y, unsigned z) { [[assume (x == 2 &amp;&amp; y &lt; 3 &amp;&amp; z &lt; 20)]]; unsigned q = x + y + z; if (q &gt; 23) call (); return 1; }&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;If we do the job correctly, the compiler figures that &lt;code&gt;q&lt;/code&gt; can never be greater than 23, eliminates the &lt;code&gt;if&lt;/code&gt; expression, and no longer makes the function call.&lt;/p&gt; &lt;h2&gt;Handling the assume expression in Ranger&lt;/h2&gt; &lt;p&gt;As I mentioned, the way GCC implements &lt;code&gt;assume&lt;/code&gt; is to outline a function that handles the assume expression as follows:&lt;/p&gt; &lt;pre&gt; &lt;code class="cpp"&gt;int assume_func (unsigned x, unsigned y, unsigned z) { if (x == 2 &amp;&amp; y &lt; 3 &amp;&amp; z &lt; 20) return 1; return 0; } int my_func (unsigned x, unsigned y, unsigned z) { assume_func (x, y, z); unsigned q = x + y + z; if (q &gt; 23) call (); return 1; } &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;GCC turns the &lt;code&gt;assume_func&lt;/code&gt; function into a sequence as follows:&lt;/p&gt; &lt;pre&gt; &lt;code class="java"&gt; tmp_3 = x == 2; tmp_5 = y &lt;= 2; tmp_9 = z &lt;= 19; tmp_1 = tmp_5 &amp; tmp_9; tmp_10 = tmp_1 &amp; tmp_3; return tmp_10;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;I don't believe that anyone could create a language construct that is more appropriate for demonstrating the power of our new range engine. All that GCC needs is to tap into Ranger and ask what the ranges of &lt;code&gt;x&lt;/code&gt;, &lt;code&gt;y&lt;/code&gt; and &lt;code&gt;z&lt;/code&gt; are if tmp_&lt;code&gt;10&lt;/code&gt; has a range of &lt;code&gt;[1, 1]&lt;/code&gt;. These would be the values we can "assume" x, y, and z have in my_func(). In a couple of days, I added the necessary tweaks, tested the feature, and checked in the changes required for support.&lt;/p&gt; &lt;p&gt;Working from the bottom to top and starting by substituting 1 for _10, we can  work our way back through the statements and determine the definitions of each expression must also be 1, resulting in expressions for x, y, and z that evaluate as follows:&lt;/p&gt; &lt;pre&gt; &lt;code class="java"&gt; 1 = x == 2; 1 = y &lt;= 2; 1 = z &lt;= 19; &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;For the result to be 1 (TRUE), we can determine the following range for &lt;code&gt;x&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt; &lt;code class="java"&gt;x → unsigned int [2, 2]&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;we can also determine the following range for &lt;code&gt;y&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt; &lt;code class="java"&gt;y → unsigned int [0, 2]&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;And finally, we can determine the following range for &lt;code&gt;z&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt; &lt;code class="java"&gt;z → unsigned int [0, 19]&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;These values of &lt;code&gt;x&lt;/code&gt;, &lt;code&gt;y&lt;/code&gt;, and &lt;code&gt;z&lt;/code&gt; are communicated back to the main program effective at the point of the &lt;code&gt;assume&lt;/code&gt; function call. GCC sees myfunc() as follows:&lt;/p&gt; &lt;pre&gt; &lt;code class="cpp"&gt;assume_func (x, y, z); tmp_1 = x + y; q = tmp_1 + z; if (q &gt; 23) call (); return 1; &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Now GCC's existing value range optimizations are able to determine that the maximum value  tmp_1 can have is 2 + 2 or 4. The maximum value &lt;code&gt;q&lt;/code&gt; can have is 4 &lt;code&gt;+19&lt;/code&gt; which is 23. This allows GCC to determine the branch can never be taken, and it can remove both the if and the call, reducing the entire function to the following:&lt;/p&gt; &lt;pre&gt; &lt;code class="cpp"&gt;return 1;&lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;The __builtin_unreachable extension: An C++23 alternative&lt;/h2&gt; &lt;p&gt;What if you don't use C++23? You can access some of the behavior of &lt;code&gt;assume&lt;/code&gt; using the GCC &lt;code&gt;__builtin_unreachable()&lt;/code&gt; extension. This function declares that the condition leading to the call can never be true (the opposite of what &lt;code&gt;assume&lt;/code&gt; says). You could therefore write the preceding program in C like so:&lt;/p&gt; &lt;pre&gt; &lt;code class="cpp"&gt;if (!(x == 2 &amp;&amp; y &lt; 3 &amp;&amp; z &lt; 20)) __builtin_unreachable (); unsigned q = x + y + z; if (q &gt; 23) call (); return 1;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The true power (or perhaps craziness?) of C++23's &lt;code&gt;assume&lt;/code&gt; functionality is that it can be arbitrarily complicated and needs to ignore side effects. This means you can write something very complex (taken from our test suite) as follows:&lt;/p&gt; &lt;pre&gt; &lt;code class="cpp"&gt;int baz (int x) { [[assume (({ int z = ++x; static int w; ++w; if (z == 51) return -1; if (z == 53) goto lab1; if (z == 64) throw 1; z == 43; }))]]; lab1: return x; }&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;GCC will see through all the complicated bits and ignore the side effects, such as the increment of &lt;code&gt;x&lt;/code&gt;, the &lt;code&gt;goto&lt;/code&gt;, and the &lt;code&gt;throw&lt;/code&gt;. GCC recognizes from this &lt;code&gt;assume&lt;/code&gt; expression that &lt;code&gt;z==43&lt;/code&gt; and &lt;code&gt;z=++x&lt;/code&gt;. The whole snippet is therefore optimized to the following:&lt;/p&gt; &lt;pre&gt; &lt;code class="cpp"&gt;return 42;&lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;We provide support for the assume feature&lt;/h2&gt; &lt;p&gt;Although GCC 13 does not have complete support for &lt;code&gt;assume&lt;/code&gt;, we do provide a functional implementation for early C++23 adopters. Give it a try. If you find an expression we can't figure out, open a bug report, and we'll fix it.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2023/02/02/support-c23-assume-feature-gcc" title="How we added support for the C++23 assume feature in GCC"&gt;How we added support for the C++23 assume feature in GCC&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Andrew MacLeod</dc:creator><dc:date>2023-02-02T07:00:00Z</dc:date></entry><entry><title>3 improvements to the OpenShift 4.12 developer experience</title><link rel="alternate" href="https://developers.redhat.com/articles/2023/02/01/3-improvements-openshift-412" /><author><name>Serena Chechile Nichols</name></author><id>fd2cbeab-7c65-4e12-8443-ebfca4fb7757</id><updated>2023-02-01T14:30:00Z</updated><published>2023-02-01T14:30:00Z</published><summary type="html">&lt;p&gt;Red Hat OpenShift Container Platform 4.12 provides several enhancements based on customer requests and usability improvements to the &lt;a href="https://developers.redhat.com/products/openshift/overview"&gt;Red Hat OpenShift &lt;/a&gt;console.&lt;/p&gt; &lt;p&gt;The improvements include the following:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;The &lt;strong&gt;Helm&lt;/strong&gt; page now has a dedicated &lt;strong&gt;Repositories&lt;/strong&gt; tab allowing users to manage Helm chart repositories.&lt;/li&gt; &lt;li&gt;When using &lt;strong&gt;OpenShift Serverless&lt;/strong&gt;, workloads created by &lt;strong&gt;Import from Git&lt;/strong&gt; and &lt;strong&gt;Deploy image&lt;/strong&gt; default to &lt;a href="https://developers.redhat.com/topics/serverless-architecture/"&gt;serverless&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;When using &lt;strong&gt;OpenShift Pipelines:&lt;/strong&gt; &lt;ul&gt;&lt;li&gt;Users now have quick access to the parameter values used during a Pipeline Run in the Parameters tab of the PipelineRun details page.&lt;/li&gt; &lt;li&gt;Users can now choose to either Cancel or Stop a running PipelineRun, providing more granular control of the running tasks of the PipelineRun.&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;li&gt;Cluster Administrators now have a form-based experience to customize areas of the OpenShift console from &lt;strong&gt;Cluster Settings&lt;/strong&gt;. Although developers cannot use this feature, it provides the ability for admins to provide an improved developer experience. Be on the lookout for an in-depth article about console customization coming soon.&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;This article will dive into what’s new for developers.&lt;/p&gt; &lt;h2&gt;3 improvements to OpenShift 4.12&lt;/h2&gt; &lt;p&gt;Let’s go into more detail about the improvements in three key areas.&lt;/p&gt; &lt;h3&gt;&lt;span&gt;1. User preferences updates&lt;/span&gt;&lt;/h3&gt; &lt;p&gt;The &lt;strong&gt;Applications&lt;/strong&gt; tab of &lt;strong&gt;User Preferences&lt;/strong&gt; provides default settings that are used in the import from Git and deploy image flows (Figure 1). In addition to security defaults, developers can now set the default workload type in the &lt;strong&gt;Resource type&lt;/strong&gt; section.  When using &lt;strong&gt;OpenShift Serverless&lt;/strong&gt;, this default is set to serverless. Otherwise, it is set to deployment.&lt;/p&gt; &lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/openshift-experience_fig1.jpg" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/openshift-experience_fig1.jpg?itok=O6poSt_X" width="600" height="357" alt="Screenshot of the applications tab of user preferences page." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 1: The applications tab of the user preferences page.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Now let’s look at how this affects the &lt;strong&gt;Import from Git&lt;/strong&gt; and &lt;strong&gt;Deploy Image&lt;/strong&gt; flows. Previously, resource type section was prominent in those user flows. We learned from users that resource type was not something that is typically changed. So once their default was set properly, they didn’t update it frequently. Because of this, we have added the ability to set the default in &lt;strong&gt;User Preferences&lt;/strong&gt; and also moved the &lt;strong&gt;Resource type&lt;/strong&gt; section of our &lt;strong&gt;Import from Git&lt;/strong&gt; and &lt;strong&gt;Deploy Image&lt;/strong&gt; forms to the &lt;strong&gt;Advanced options&lt;/strong&gt; section (see Figure 2).&lt;/p&gt; &lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/openshift-experience-fig2.jpg" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/openshift-experience-fig2.jpg?itok=AdTt9kqI" width="600" height="293" alt="Screenshot of the previous and new advanced options page with the Resource type section." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 2: The Resource type section moved to the Advanced option section.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;2. Improved display of limits and quotas issues&lt;/h3&gt; &lt;p&gt;To improve awareness of project limits and quota issues, developers will see a warning label on the top of the &lt;strong&gt;Add&lt;/strong&gt; and &lt;strong&gt;Topology&lt;/strong&gt; page when any project limits and quotas are detected. Figure 3 shows an example of the label on the &lt;strong&gt;Topology&lt;/strong&gt; page, which indicates the number of quotas that have been reached. Developers can click the label to get additional data to detect the issue.&lt;/p&gt; &lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/openshift-experience-fig3.jpg" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/openshift-experience-fig3.jpg?itok=AT8xaJDt" width="600" height="267" alt="A screenshot of the quota issues label on the topology page." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 3: The quota issues label on the Topology page indicating the number of quotas reached.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;When multiple quotas have been reached, the user is brought to the list page of Resource Quotas (see Figure 4). Otherwise, users will be redirected to the details page of that specific resource quota.&lt;/p&gt; &lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/openshift-experience-fig4.jpg" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/openshift-experience-fig4.jpg?itok=RE3qinFD" width="600" height="242" alt="The Resource Quotas page showing resources reached quotas." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 4: The Resource Quotas page showing resources reached quotas.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Taking this a step further, additional visual indicators are shown in &lt;strong&gt;Topology&lt;/strong&gt; on resources that have surpassed limits or quotas. Figure 5 illustrates an example of how developers can identify these issues at different zoom levels. Developers can gain additional information about the detected problem by clicking on the node and viewing the information in the side panel. An in-context link is provided, allowing the developer to navigate to the specific flow to fix the issue. In this case, it would allow them to edit the resource limits of the deployment.&lt;/p&gt; &lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/openshift-experience-fig5.jpg" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/openshift-experience-fig5.jpg?itok=hxyiGU9W" width="600" height="266" alt="A screenshot of issues at different zoom levels." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 5: You can view issues at different zoom levels.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;This is one of my favorite features of the release. Currently, when limits and quotas are reached, developers have to go to the &lt;strong&gt;Project Details&lt;/strong&gt; page to get information. We now inform the user as soon as the issue is detected. Additionally, we provide them with one-click access to either get more information or resolve the issue (Figure 6).&lt;/p&gt; &lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/openshift-exp-fig6-img7.jpg" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/openshift-exp-fig6-img7.jpg?itok=c9cCdx2D" width="600" height="314" alt="One-click access to resolve the issue." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 6: One-click access to learn how to resolve the issue.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;3. End-to-end KafkaSink support&lt;/h3&gt; &lt;p&gt;Receive and store CloudEvents from Source/Subscription/Trigger on a Kafka topic without writing custom code as follows:&lt;/p&gt; &lt;p&gt;When the CR for knativeKafka is created with sink enabled, developers can create a KafkaSink from the Event Sink Catalog. Users will have a form-based experience to create a KafkaSink (Figure 7). Once created, a KafkaSink can be added as subscriber, trigger, and event-source sink targets. Developers can accomplish by using drag-and-drop or the action buttons.&lt;/p&gt; &lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/openshift-experience-fig6.jpg" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/openshift-experience-fig6.jpg?itok=ra4ih8cj" width="600" height="341" alt="The form-based creation flow for KafkaSink." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 7: The form-based creation flow for KafkaSink.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;How to get started with OpenShift 4.12&lt;/h2&gt; &lt;p&gt;Ready to try these new features for yourself? Get started with OpenShift 4.12 today on the &lt;a href="https://www.redhat.com/en/technologies/cloud-computing/openshift/openshift-developer-sandbox-trial"&gt;Developer Sandbox&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Check out the following resources to learn more about the new OpenShift 4.12 release:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=BwIKMBhj3mQ"&gt;What's New in OpenShift 4.12 [Developer Edition]&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://www.youtube.com/c/RedHatDevelopers"&gt;Red Hat Developer YouTube channel&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://www.redhat.com/en/technologies/cloud-computing/openshift/try-it"&gt;Try Red Hat OpenShift&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;If you have questions, feel free to comment below or reach out to us. Community feedback helps us to continually improve the OpenShift developer experience. Tweet me &lt;a href="http://twitter.com/serenamarie125"&gt;@serenamarie125&lt;/a&gt; or join the &lt;a href="https://groups.google.com/g/openshift-dev-users"&gt;OpenShift Developer Experience Google group&lt;/a&gt; to share your feedback.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2023/02/01/3-improvements-openshift-412" title="3 improvements to the OpenShift 4.12 developer experience"&gt;3 improvements to the OpenShift 4.12 developer experience&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Serena Chechile Nichols</dc:creator><dc:date>2023-02-01T14:30:00Z</dc:date></entry><entry><title type="html">New Feature: Dashbuilder editor with IntelliSense capabilities</title><link rel="alternate" href="https://blog.kie.org/2023/02/new-feature-dashbuilder-editor-with-intellisense-capabilities.html" /><author><name>Ajay Jaganathan</name></author><id>https://blog.kie.org/2023/02/new-feature-dashbuilder-editor-with-intellisense-capabilities.html</id><updated>2023-02-01T14:02:58Z</updated><content type="html">We are pleased to announce that the dashbuilder editor now ships with auto-complete capabilities! This enhances the user experience by providing suggestions and helps to reduce the errors made while authoring the dashbuilder specification.  Let’s go through the new features in the below section: AUTO-COMPLETE SUGGESTIONS: While typing out a particular word or pressing ctrl+space, the editor provides the list of possible values for that particular context. The user can select the appropriate one from the list of possible values and automatically complete it. If any required field is missing, it also prompts the user with error messages. Below is a short video of the auto-complete capability in action. Autocomplete while authoring CREATING A SAMPLE DASHBUILDER SPECIFICATION(CODE LENS): When starting with an empty file, the editor provides a code lens to auto-fill the file with a sample dashbuilder specification. This gives the user some boilerplate code to start authoring the specification. Below is a sample video of the code lens feature in action. Codelens in action CONCLUSION These features are implemented to reduce the complexity of authoring a dashboard and the errors made while doing it. These features are available in all of our extensions! Stay tuned to learn more about the new features planned for . The post appeared first on .</content><dc:creator>Ajay Jaganathan</dc:creator></entry><entry><title>Quarkus 2.16.1.Final released - Maintenance release</title><link rel="alternate" href="&#xA;                https://quarkus.io/blog/quarkus-2-16-1-final-released/&#xA;            " /><author><name>Guillaume Smet (https://twitter.com/gsmet_)</name></author><id>https://quarkus.io/blog/quarkus-2-16-1-final-released/</id><updated>2023-02-01T00:00:00Z</updated><published>2023-02-01T00:00:00Z</published><summary type="html">We released Quarkus 2.16.1.Final, our first maintenance release for the 2.16 release train. As usual, it contains bugfixes and documentation improvements. It should be a safe upgrade for anyone already using 2.16. For people using Micrometer, the format used to export metrics has changed in 2.16 (for the Prometheus format),...</summary><dc:creator>Guillaume Smet (https://twitter.com/gsmet_)</dc:creator><dc:date>2023-02-01T00:00:00Z</dc:date></entry></feed>
